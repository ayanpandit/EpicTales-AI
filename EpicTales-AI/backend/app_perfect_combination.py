from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import logging
import time
import requests
import base64
import io
from PIL import Image, ImageDraw, ImageFont
import json

# Import image generation from img.py approach
try:
    from huggingface_hub import InferenceClient
    HAS_CLIENT = True
except Exception:
    HAS_CLIENT = False

app = Flask(__name__)
# Configure CORS to allow specific origins and methods
CORS(app, origins=["http://localhost:3000", "http://localhost:5173"], 
     methods=["GET", "POST"], 
     allow_headers=["Content-Type"])

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create static directory if it doesn't exist
os.makedirs('static', exist_ok=True)

# Initialize models with lazy loading
text_gen = None

# IMAGE GENERATION CONFIG (from img.py)
TOKEN = os.environ.get("HUGGINGFACEHUB_API_TOKEN") or "paste your api key here"
MODEL_CANDIDATES = [
    "stabilityai/stable-diffusion-2-1",
    "stabilityai/stable-diffusion-xl-base-1.0",
    "prompthero/openjourney-v4",
    "stable-diffusion-v1-5/stable-diffusion-v1-5",
    "CompVis/stable-diffusion-v1-4",
]
HTTP_TIMEOUT = 60

def initialize_text_model():
    """Initialize text generation model - FROM app_guaranteed.py (WORKING)"""
    global text_gen
    if text_gen is None:
        try:
            logger.info("üìñ Loading text generation model...")
            from transformers import pipeline
            import warnings
            warnings.filterwarnings("ignore")
            
            text_gen = pipeline("text-generation", model="gpt2")
            logger.info("‚úÖ Text generation model loaded successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to load text generation model: {e}")
    return text_gen

def generate_story_segment(prompt):
    """Generate story text - FROM app_guaranteed.py (WORKING PERFECTLY)"""
    try:
        model = initialize_text_model()
        if model is None:
            return "Text generation temporarily unavailable. Please try again later."
        
        # Limit prompt length to avoid token limits
        if len(prompt) > 400:
            prompt = prompt[:400]
            
        # Generate with better parameters
        outputs = model(
            prompt, 
            max_new_tokens=80, 
            do_sample=True, 
            temperature=0.8,
            pad_token_id=50256
        )
        generated_text = outputs[0]['generated_text']
        
        # Extract only the newly generated part
        new_text = generated_text[len(prompt):].strip()
        return new_text if new_text else "Story generation completed."
        
    except Exception as e:
        logger.error(f"Error generating story segment: {e}")
        return f"Story generation error: {str(e)}"

def sanitize_filename(model_id):
    """Helper for filename from img.py"""
    return model_id.replace("/", "_").replace(" ", "_")

def try_with_inference_client(prompt, model, scene_name):
    """Image generation using InferenceClient - FROM img.py (WORKING)"""
    if not HAS_CLIENT:
        return False, "huggingface_hub.InferenceClient not installed"
    try:
        client = InferenceClient(token=TOKEN)
        logger.info(f"üé® InferenceClient: requesting model '{model}' for {scene_name}...")
        
        # Generate image
        image = client.text_to_image(prompt, model=model)
        
        # Handle list response
        if isinstance(image, list):
            image = image[0]
        
        # Save with scene-specific filename
        timestamp = int(time.time())
        out_fname = f"hf_{scene_name.lower().replace(' ', '_')}_{sanitize_filename(model)}_{timestamp}.png"
        img_path = os.path.join("static", out_fname)
        image.save(img_path)
        
        logger.info(f"‚úÖ Saved image: {out_fname}")
        return True, out_fname
        
    except Exception as e:
        return False, f"InferenceClient error: {repr(e)}"

def try_with_http_api(prompt, model, scene_name):
    """Image generation using HTTP API - FROM img.py (WORKING)"""
    endpoint = f"https://api-inference.huggingface.co/models/{model}"
    headers = {"Authorization": f"Bearer {TOKEN}"}
    payload = {
        "inputs": prompt,
        "options": {"wait_for_model": True}
    }
    
    try:
        logger.info(f"üåê HTTP: POST {endpoint} for {scene_name}...")
        r = requests.post(endpoint, headers=headers, json=payload, timeout=HTTP_TIMEOUT)
    except requests.exceptions.RequestException as e:
        return False, f"HTTP request failed: {e}"

    status = r.status_code
    ctype = r.headers.get("content-type", "")
    
    if status == 200 and ctype.startswith("image"):
        timestamp = int(time.time())
        out_fname = f"hf_http_{scene_name.lower().replace(' ', '_')}_{sanitize_filename(model)}_{timestamp}.png"
        img_path = os.path.join("static", out_fname)
        
        try:
            with open(img_path, "wb") as f:
                f.write(r.content)
            logger.info(f"‚úÖ Saved image: {out_fname}")
            return True, out_fname
        except Exception as e:
            return False, f"Failed to write image file: {e}"

    # Handle JSON error response
    try:
        j = r.json()
        return False, f"Status {status}: {j}"
    except Exception:
        return False, f"Status {status}: {r.text[:400]}"

def generate_real_image_huggingface(prompt, scene_name, art_style="cartoon"):
    """Generate REAL images using Hugging Face API - FROM img.py (WORKING PERFECTLY)"""
    
    if TOKEN is None or TOKEN.strip() == "" or TOKEN.startswith("<PASTE"):
        logger.error("‚ùå No Hugging Face token found")
        return None
    
    # Clean and enhance the prompt
    clean_prompt = prompt.replace('\n', ' ').strip()
    if len(clean_prompt) > 100:
        clean_prompt = clean_prompt[:100]
    
    # Create style-specific prompt
    style_prompts = {
        "cartoon": "cartoon style, animated, colorful, simple, child-friendly",
        "realistic": "photorealistic, detailed, high quality, professional",
        "anime": "anime style, manga, vibrant colors, detailed",
        "watercolor": "watercolor painting, soft colors, artistic, painted"
    }
    
    style_text = style_prompts.get(art_style, "digital art, colorful")
    full_prompt = f"{clean_prompt}, {style_text}, storybook illustration, high quality"
    
    logger.info(f"üé® REAL IMAGE GENERATION for {scene_name} with prompt: {full_prompt[:60]}...")
    
    # Try each model in sequence - FROM img.py approach
    for model in MODEL_CANDIDATES:
        logger.info(f"üîÑ Trying model: {model}")
        
        # 1) Try InferenceClient first (preferred)
        if HAS_CLIENT:
            ok, result = try_with_inference_client(full_prompt, model, scene_name)
            if ok:
                logger.info(f"‚úÖ InferenceClient SUCCESS for {scene_name}! File: {result}")
                return result
            else:
                logger.warning(f"‚ö†Ô∏è InferenceClient failed: {result}")

        # 2) Try HTTP API fallback
        ok, result = try_with_http_api(full_prompt, model, scene_name)
        if ok:
            logger.info(f"‚úÖ HTTP API SUCCESS for {scene_name}! File: {result}")
            return result
        else:
            logger.warning(f"‚ö†Ô∏è HTTP API failed: {result}")
            time.sleep(1)  # Brief pause before trying next model
    
    # If all models failed
    logger.error(f"‚ùå All Hugging Face models failed for {scene_name}")
    return None

def create_fallback_image(scene_name, story_text, art_style):
    """Create beautiful fallback image when API fails"""
    try:
        logger.info(f"üé® Creating fallback image for {scene_name}...")
        
        # Create high-quality fallback
        img = Image.new('RGB', (768, 768), color='#1a1a2e')
        draw = ImageDraw.Draw(img)
        
        # Art style color schemes
        color_schemes = {
            "cartoon": {"bg": "#ff6b6b", "accent": "#4ecdc4", "text": "#ffffff"},
            "realistic": {"bg": "#2c3e50", "accent": "#3498db", "text": "#ecf0f1"},
            "anime": {"bg": "#8e44ad", "accent": "#f39c12", "text": "#ffffff"},
            "watercolor": {"bg": "#74b9ff", "accent": "#fd79a8", "text": "#2d3436"},
            "default": {"bg": "#4a5568", "accent": "#ed8936", "text": "#f7fafc"}
        }
        
        colors = color_schemes.get(art_style, color_schemes["default"])
        
        # Create gradient background
        bg_rgb = tuple(int(colors["bg"][i:i+2], 16) for i in (1, 3, 5))
        accent_rgb = tuple(int(colors["accent"][i:i+2], 16) for i in (1, 3, 5))
        
        for y in range(768):
            blend = y / 768
            r = int(bg_rgb[0] * (1-blend) + accent_rgb[0] * blend)
            g = int(bg_rgb[1] * (1-blend) + accent_rgb[1] * blend)
            b = int(bg_rgb[2] * (1-blend) + accent_rgb[2] * blend)
            draw.line([(0, y), (768, y)], fill=(r, g, b))
        
        # Add decorative elements
        scene_elements = {
            "Introduction": "‚ú® üè∞ ‚ú®",
            "Rising Action": "‚ö° üó°Ô∏è ‚ö°", 
            "Climax": "üí• ‚≠ê üí•",
            "Resolution": "üåü üëë üåü"
        }
        
        decoration = scene_elements.get(scene_name, "üé® ‚ú® üé®")
        
        # Load fonts
        try:
            title_font = ImageFont.truetype("arial.ttf", 48)
            text_font = ImageFont.truetype("arial.ttf", 20)
        except:
            title_font = ImageFont.load_default()
            text_font = ImageFont.load_default()
        
        # Add text content
        lines = [
            decoration,
            "",
            scene_name.upper(),
            "",
            "üé® AI IMAGE GENERATION", 
            "API Temporarily Busy",
            "",
            "üìñ Story Preview:",
            story_text[:80] + "..." if len(story_text) > 80 else story_text,
            "",
            f"üé≠ Style: {art_style.title()}",
            "‚ú® Real images will load next time"
        ]
        
        y_pos = 120
        for i, line in enumerate(lines):
            if line:
                font = title_font if i in [0, 2] else text_font
                color = accent_rgb if i in [0, 2] else (255, 255, 255)
                
                # Center text
                bbox = draw.textbbox((0, 0), line, font=font)
                text_width = bbox[2] - bbox[0]
                x_pos = (768 - text_width) // 2
                
                # Add shadow
                draw.text((x_pos + 2, y_pos + 2), line, fill=(0, 0, 0, 128), font=font)
                draw.text((x_pos, y_pos), line, fill=color, font=font)
            
            y_pos += 45 if i in [0, 2] else 30
        
        # Save fallback image
        timestamp = int(time.time())
        img_filename = f"fallback_{scene_name.lower().replace(' ', '_')}_{timestamp}.png"
        img_path = os.path.join("static", img_filename)
        img.save(img_path, "PNG", quality=95)
        
        logger.info(f"‚úÖ Created fallback image: {img_filename}")
        return img_filename
        
    except Exception as e:
        logger.error(f"‚ùå Error creating fallback image: {e}")
        return None

def generate_image_perfect_combination(prompt, scene_name, art_style="cartoon"):
    """PERFECT COMBINATION: Use img.py approach for REAL images with fallback"""
    
    # Method 1: Try Hugging Face API (from img.py) - REAL IMAGES
    try:
        logger.info(f"üé® Method 1: Hugging Face API for {scene_name}...")
        result = generate_real_image_huggingface(prompt, scene_name, art_style)
        if result:
            logger.info(f"üéâ REAL IMAGE SUCCESS for {scene_name}!")
            return result
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Method 1 failed: {e}")
    
    # Method 2: Beautiful fallback image
    try:
        logger.info(f"üé® Method 2: Creating beautiful fallback for {scene_name}...")
        result = create_fallback_image(scene_name, prompt, art_style)
        if result:
            logger.info(f"‚úÖ Fallback image created for {scene_name}!")
            return result
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Method 2 failed: {e}")
    
    # Method 3: Simple emergency fallback
    try:
        logger.info(f"üìù Method 3: Emergency fallback for {scene_name}...")
        img = Image.new('RGB', (512, 512), color='#2d3748')
        draw = ImageDraw.Draw(img)
        
        text = f"{scene_name}\n\nImage generation\ntemporarily unavailable"
        
        try:
            font = ImageFont.truetype("arial.ttf", 24)
        except:
            font = ImageFont.load_default()
        
        # Center text
        lines = text.split('\n')
        y_start = 200
        for line in lines:
            if line.strip():
                bbox = draw.textbbox((0, 0), line, font=font)
                text_width = bbox[2] - bbox[0]
                x_pos = (512 - text_width) // 2
                draw.text((x_pos, y_start), line, fill='white', font=font)
            y_start += 40
        
        timestamp = int(time.time())
        img_filename = f"emergency_{scene_name.lower().replace(' ', '_')}_{timestamp}.png"
        img_path = os.path.join("static", img_filename)
        img.save(img_path)
        
        logger.info(f"üìù Emergency fallback created: {img_filename}")
        return img_filename
        
    except Exception as e:
        logger.error(f"‚ùå All image generation methods failed: {e}")
        return None

@app.route('/generate', methods=['POST'])
def generate():
    """PERFECT COMBINATION: Story from app_guaranteed + Images from img.py"""
    try:
        # Validate request data
        if not request.is_json:
            return jsonify({"error": "Request must be JSON"}), 400
            
        data = request.json
        story_idea = data.get("story_idea", "").strip()
        genre = data.get("genre", "fantasy")
        tone = data.get("tone", "lighthearted")
        art_style = data.get("art_style", "cartoon")
        audience = data.get("audience", "all")

        # Validate required fields
        if not story_idea:
            return jsonify({"error": "Story idea is required"}), 400

        # Define story scenes
        scenes = ["Introduction", "Rising Action", "Climax", "Resolution"]
        story = {}
        images = {}

        logger.info(f"üéØ PERFECT COMBINATION GENERATION - Story: '{story_idea[:50]}...'")
        logger.info(f"üìñ Story generation: app_guaranteed.py method")
        logger.info(f"üé® Image generation: img.py method (Hugging Face API)")

        # Generate content for each scene
        for i, scene in enumerate(scenes):
            try:
                # Story generation using app_guaranteed.py method (WORKING)
                scene_context = {
                    "Introduction": "Begin the story by introducing the main character and setting",
                    "Rising Action": "Develop the conflict and build tension",
                    "Climax": "Reach the most exciting or turning point of the story", 
                    "Resolution": "Conclude the story and resolve the conflict"
                }
                
                prompt = f"{scene_context[scene]} for a {genre} story with a {tone} tone suitable for {audience}. Story concept: {story_idea}. {scene}: "
                
                logger.info(f"üìñ Generating story for {scene} ({i+1}/4)...")
                text = generate_story_segment(prompt)
                story[scene] = text

                # Image generation using img.py method (WORKING)
                logger.info(f"üé® Generating REAL image for {scene} ({i+1}/4)...")
                visual_prompt = f"{story_idea}, {text[:60]}, {scene.lower()}, {art_style} style"
                img_filename = generate_image_perfect_combination(visual_prompt, scene, art_style)
                
                if img_filename:
                    images[scene] = f"/static/{img_filename}"
                    logger.info(f"‚úÖ COMPLETE SUCCESS for {scene}: Story + Image")
                else:
                    logger.error(f"üö® No image generated for {scene}")
                    images[scene] = None
                
            except Exception as e:
                logger.error(f"‚ùå Error generating {scene}: {e}")
                story[scene] = f"Error generating {scene}. Please try again."
                images[scene] = None

        # Count successful images
        successful_images = sum(1 for img in images.values() if img is not None)
        logger.info(f"üéâ PERFECT COMBINATION COMPLETE: {successful_images}/4 scenes with images")

        response_data = {
            "success": True,
            "story": story,
            "images": images,
            "metadata": {
                "genre": genre,
                "tone": tone,
                "art_style": art_style,
                "audience": audience,
                "images_generated": successful_images,
                "total_scenes": len(scenes),
                "story_method": "app_guaranteed.py",
                "image_method": "img.py_huggingface_api",
                "generation_method": "perfect_combination"
            }
        }

        return jsonify(response_data)

    except Exception as e:
        logger.error(f"‚ùå Critical error in perfect combination: {e}")
        return jsonify({
            "success": False,
            "error": f"Server error: {str(e)}"
        }), 500

@app.route('/static/<filename>')
def serve_static(filename):
    """Serve static files (images)"""
    try:
        return send_from_directory('static', filename)
    except Exception as e:
        logger.error(f"Error serving static file {filename}: {e}")
        return jsonify({"error": "File not found"}), 404

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "story_generation": "app_guaranteed.py_method",
        "image_generation": "img.py_huggingface_api",
        "combination": "perfect",
        "note": "Best of both worlds: Working stories + Working images"
    })

@app.route('/test', methods=['GET'])
def test_endpoint():
    """Simple test endpoint"""
    return jsonify({
        "message": "Perfect Combination Backend Working!",
        "timestamp": time.time(),
        "story_source": "app_guaranteed.py",
        "image_source": "img.py",
        "combination": "perfect"
    })

if __name__ == "__main__":
    # Change to the script's directory to ensure static files work
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    logger.info("üéØ Starting PERFECT COMBINATION AI Storybook Backend...")
    logger.info(f"üìÅ Working directory: {os.getcwd()}")
    logger.info("üìç Frontend should connect to: http://localhost:5000")
    logger.info("=" * 60)
    logger.info("üéØ PERFECT COMBINATION:")
    logger.info("   üìñ Story Generation: app_guaranteed.py method (WORKING)")
    logger.info("   üé® Image Generation: img.py method (WORKING)")
    logger.info("   üîó Hugging Face API Token: Configured")
    logger.info("   ‚ú® Result: BOTH stories AND images working!")
    logger.info("=" * 60)
    logger.info("üí° You get the BEST of both files combined!")
    app.run(debug=True, host='0.0.0.0', port=5000)
